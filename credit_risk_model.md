好的 👍，我来帮你梳理一下 **PD、EAD、LGD** 这三个是信用风险建模的核心概念，特别是银行在 **Basel 协议（巴塞尔协议 II / III）** 框架下都要用到的指标。

---

## 📌 三个关键指标

### 1. **PD (Probability of Default)**

* 中文：违约概率
* 定义：借款人在 **未来一定时间（通常是一年）** 内发生违约的概率。
* 数学：

  $$
  PD = P(\text{Borrower Defaults within time horizon})
  $$
* 例子：

  * 一个客户的 PD = 5% → 意味着在未来 12 个月内，这个客户有 5% 的可能违约。
* 商业意义：

  * 用来区分 **高风险客户** 和 **低风险客户**。
  * 在银行内部 PD 常作为 **评级系统** 的结果，比如 AAA 客户的 PD 很低，C 客户的 PD 很高。

---

### 2. **EAD (Exposure at Default)**

* 中文：违约时风险敞口
* 定义：客户在违约时，银行实际暴露的风险金额（即违约发生时，客户尚未偿还的金额）。
* 数学：

  $$
  EAD = \text{Outstanding Balance at Default}
  $$
* 例子：

  * 客户申请了一笔信用卡额度 10,000，加上利息和未还金额，违约时余额是 8,000 → 那么 EAD = 8,000。
* 商业意义：

  * 银行要准确估计违约时可能“踩雷”的金额，用于资本计提和风险管理。

---

### 3. **LGD (Loss Given Default)**

* 中文：违约损失率
* 定义：客户违约时，银行在 **EAD 中无法收回的比例**。
* 数学：

  $$
  LGD = \frac{\text{Loss at Default}}{\text{EAD}}
  $$
* 例子：

  * 客户违约时余额（EAD）是 100 万，最后银行通过抵押物收回了 40 万 → 实际损失 60 万 →

  $$
  LGD = 60\% 
  $$
* 商业意义：

  * 银行需要估算违约后能收回多少。比如抵押贷款 LGD 通常较低（因为有房产担保），而无抵押信用卡 LGD 较高。

---

## 📊 三者结合 → 预期损失 (Expected Loss, EL)

银行用这三个指标计算 **预期损失**：

$$
EL = PD \times EAD \times LGD
$$

### 例子

* 客户贷款余额（EAD）= 100,000
* 违约概率（PD）= 2%
* 损失率（LGD）= 40%

$$
EL = 0.02 \times 100,000 \times 0.40 = 800
$$

👉 也就是说，这笔贷款的年预期损失是 **800**。

---

## 🏦 在银行中的应用场景

* **定价**：利率要覆盖预期损失 + 成本 + 利润 → 高 PD/LGD 客户 → 利率更高
* **资本要求**：监管要求银行按 PD、EAD、LGD 计算风险加权资产 (RWA)，决定要准备多少资本
* **组合管理**：区分零售贷款 vs 企业贷款，不同的 LGD 假设（抵押贷款 vs 信用卡）
* **压力测试**：假设经济衰退时 PD/LGD 上升，看银行资本是否足够

---

要不要我结合你给的 **贷款数据集**（Age, Income, LoanAmount, CreditScore 等），做一个小型 Python 示例：

* 先用决策树预测 **PD**（违约概率）
* 再随机生成 EAD（贷款余额）和 LGD（假设抵押贷款 vs 信用卡），
* 最后算出 Expected Loss？




### **1. 传统统计模型**

这些模型具有很好的可解释性，金融机构尤其在监管环境下常用它们：

* **逻辑回归（Logistic Regression）**

  * 用于分类问题，例如预测客户是否违约（PD）。
  * 优点：模型易解释、可以输出概率。
  * 示例：`PD = 1 / (1 + exp(-(β0 + β1*X1 + ... + βn*Xn)))`
* **判别分析（LDA/QDA）**

  * 线性/二次判别分析，用于区分高风险与低风险客户。
* **Probit 模型**

  * 类似 Logistic 回归，但假设误差服从正态分布。

---

### **2. 树模型（Tree-based Models）**

* **决策树（Decision Tree）**

  * 优点：直观、可解释。
  * 缺点：容易过拟合。
* **随机森林（Random Forest）**

  * 通过多棵树投票降低过拟合。
  * 可以输出特征重要性，帮助风险控制分析。
* **梯度提升树（Gradient Boosting, 如 XGBoost、LightGBM、CatBoost）**

  * 在信用评分中非常流行，能够处理非线性关系。
  * 优点：预测准确率高，适合处理大规模数据。
  * 示例应用：PD 模型、信用卡违约预测、欺诈检测。

---

### **3. 支持向量机（SVM）**

* 用于小样本、高维数据场景。
* 可以通过核函数处理非线性分界。
* 在信用风险中不如树模型常用，因为解释性差。

---

### **4. 神经网络（Neural Networks / Deep Learning）**

* 适合大数据、非线性关系复杂的场景。
* 可用于：

  * PD、LGD、EAD预测。
  * 异常交易或欺诈检测。
* 缺点：可解释性差，监管要求下不易直接使用。
* 常用结构：MLP（多层感知机）、LSTM（时间序列数据）。

---

### **5. 集成与混合模型**

* **堆叠模型（Stacking）**：将逻辑回归、随机森林、XGBoost等组合。
* **Bagging / Boosting**：提高模型稳定性和准确率。
* 在银行风控实践中，通常会做模型组合，既保证 **准确率** 又保证一定的 **解释性**。

---

### **6. 非监督学习（Unsupervised Learning）**

* 用于欺诈检测或客户分群。
* 常用算法：

  * K-means
  * DBSCAN / HDBSCAN
  * Isolation Forest（异常值检测）
* 可以发现潜在高风险客户或异常行为。

---

### **7. 模型选择考量**

在信用风险建模中：

1. **可解释性要求高** → Logistic 回归、决策树。
2. **准确率要求高** → XGBoost、LightGBM、随机森林。
3. **监管报告与审计** → 模型要透明，可输出概率和特征重要性。
4. **样本不平衡问题** → 需要用 **SMOTE、加权损失函数或分层抽样** 处理违约样本稀少的情况。

